#!/usr/bin/env python3
"""
AI-powered –ø–∞—Ä—Å–µ—Ä —Ç–∞–±–ª–∏—Ü —á–µ—Ä–µ–∑ ChatGPT
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–Ω–∏–º–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü –±–µ–∑ —Ä—É—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
"""

import pandas as pd
import requests
import json
import logging
import os
import time
from typing import Dict, List, Any, Optional, Tuple
from .base_parser import BaseParser

logger = logging.getLogger(__name__)

class AITableParser(BaseParser):
    """AI-powered –ø–∞—Ä—Å–µ—Ä —Ç–∞–±–ª–∏—Ü —á–µ—Ä–µ–∑ ChatGPT"""
    
    def __init__(self, openai_api_key: str):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—â–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π
        super().__init__()
        
        self.api_key = openai_api_key
        self.max_rows_for_analysis = 100  # –£–º–µ–Ω—å—à–∞–µ–º –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –∏–∑–±–µ–∂–∞–Ω–∏—è —Ç–∞–π–º–∞—É—Ç–æ–≤
        self.max_tokens = 8000  # –£–º–µ–Ω—å—à–∞–µ–º –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        
    def analyze_table_structure(self, df: pd.DataFrame, context: str = "") -> Optional[Dict]:
        """
        –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã —á–µ—Ä–µ–∑ ChatGPT
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–æ–ª–±—Ü–∞—Ö –∏ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–∞—Ö
        """
        try:
            if df.empty:
                return None
            
            # –ì–æ—Ç–æ–≤–∏–º –æ–±—Ä–∞–∑–µ—Ü —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            table_sample = self._prepare_table_sample(df)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è ChatGPT
            prompt = self._create_analysis_prompt(table_sample, context)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ ChatGPT
            response = self._query_chatgpt(prompt)
            
            if response:
                return self._parse_chatgpt_response(response, df)
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ AI –∞–Ω–∞–ª–∏–∑–∞ —Ç–∞–±–ª–∏—Ü—ã: {e}")
            return None
    
    def _prepare_table_sample(self, df: pd.DataFrame) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–±—Ä–∞–∑—Ü–∞ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ ChatGPT"""
        # –£–º–Ω–æ–µ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ: –±–µ—Ä–µ–º –Ω–∞—á–∞–ª–æ, —Å–µ—Ä–µ–¥–∏–Ω—É –∏ –∫–æ–Ω–µ—Ü —Ç–∞–±–ª–∏—Ü—ã
        if len(df) <= self.max_rows_for_analysis:
            # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –º–∞–ª–µ–Ω—å–∫–∞—è - –±–µ—Ä–µ–º –≤—Å—é
            sample_df = df.copy()
            logger.info(f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å—é —Ç–∞–±–ª–∏—Ü—É: {len(df)} —Å—Ç—Ä–æ–∫")
        else:
            # –î–ª—è –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü –±–µ—Ä–µ–º: –Ω–∞—á–∞–ª–æ (40%), —Å–µ—Ä–µ–¥–∏–Ω—É (40%), –∫–æ–Ω–µ—Ü (20%)
            total_rows = self.max_rows_for_analysis
            start_rows = int(total_rows * 0.4)  # 200 —Å—Ç—Ä–æ–∫
            middle_rows = int(total_rows * 0.4)  # 200 —Å—Ç—Ä–æ–∫  
            end_rows = total_rows - start_rows - middle_rows  # 100 —Å—Ç—Ä–æ–∫
            
            # –ù–∞—á–∞–ª–æ —Ç–∞–±–ª–∏—Ü—ã
            start_df = df.head(start_rows)
            
            # –°–µ—Ä–µ–¥–∏–Ω–∞ —Ç–∞–±–ª–∏—Ü—ã
            middle_start = len(df) // 2 - middle_rows // 2
            middle_end = middle_start + middle_rows
            middle_df = df.iloc[middle_start:middle_end]
            
            # –ö–æ–Ω–µ—Ü —Ç–∞–±–ª–∏—Ü—ã
            end_df = df.tail(end_rows)
            
            logger.info(f"üìä –£–º–Ω–æ–µ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑ {len(df)} —Å—Ç—Ä–æ–∫:")
            logger.info(f"   üìç –ù–∞—á–∞–ª–æ: —Å—Ç—Ä–æ–∫–∏ 0-{start_rows-1} ({start_rows} —Å—Ç—Ä–æ–∫)")
            logger.info(f"   üìç –°–µ—Ä–µ–¥–∏–Ω–∞: —Å—Ç—Ä–æ–∫–∏ {middle_start}-{middle_end-1} ({middle_rows} —Å—Ç—Ä–æ–∫)")
            logger.info(f"   üìç –ö–æ–Ω–µ—Ü: –ø–æ—Å–ª–µ–¥–Ω–∏–µ {end_rows} —Å—Ç—Ä–æ–∫")
            logger.info(f"   üìä –ò—Ç–æ–≥–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {total_rows} —Å—Ç—Ä–æ–∫")
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏
            sample_df = pd.concat([start_df, middle_df, end_df], ignore_index=True)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
        table_text = ""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
        headers = [str(col) if pd.notna(col) and str(col).strip() else f"Col{i}" for i, col in enumerate(df.columns)]
        table_text += "COLUMNS: " + " | ".join(headers) + "\\n\\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        for idx, row in sample_df.iterrows():
            row_data = []
            for col in df.columns:
                value = str(row[col]).strip() if pd.notna(row[col]) else ""
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —è—á–µ–π–∫–∏
                if len(value) > 50:
                    value = value[:47] + "..."
                row_data.append(value)
            
            table_text += f"Row{idx}: " + " | ".join(row_data) + "\\n"
        
        return table_text
    
    def _create_analysis_prompt(self, table_sample: str, context: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã"""
        
        prompt = f"""–ò–∑–≤–ª–µ–∫–∏ –í–°–ï —Ç–æ–≤–∞—Ä—ã –∏–∑ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞. –°—Ç—Ä–æ–∫–∏ –∏ —Å—Ç–æ–ª–±—Ü—ã –Ω—É–º–µ—Ä—É—é—Ç—Å—è —Å –Ω—É–ª—è.

### BEGIN_TABLE
{table_sample}
### END_TABLE

–ö–û–ù–¢–ï–ö–°–¢: {context if context else "–ü—Ä–∞–π—Å-–ª–∏—Å—Ç —Ç–æ–≤–∞—Ä–æ–≤"}

–ê–õ–ì–û–†–ò–¢–ú –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø:
1. –ó–ê–ì–û–õ–û–í–ö–ò: –ù–∞–π–¥–∏ —Å—Ç—Ä–æ–∫—É —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ —Å—Ç–æ–ª–±—Ü–æ–≤. –ò—â–∏ —Å–∏–Ω–æ–Ω–∏–º—ã:
   - –¢–æ–≤–∞—Ä—ã: "Item", "Product", "Name", "Description", "Nama Barang", "Artikel"
   - –¶–µ–Ω—ã: "Price", "Harga", "Cost", "Amount", "Total", "Sum"
   - –ï–¥–∏–Ω–∏—Ü—ã: "Unit", "UOM", "Qty", "Quantity", "Satuan", "Kemasan"
   - –†–∞–∑–º–µ—Ä—ã: "Size", "Volume", "Weight", "Ukuran", "Berat"

2. –§–ò–õ–¨–¢–†–ê–¶–ò–Ø: –ò–∑–≤–ª–µ–∫–∞–π —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ –≥–¥–µ:
   - –ï—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ (–Ω–µ –ø—É—Å—Ç–æ–µ)
   - –¶–µ–Ω–∞ = –ß–ò–°–õ–û (–∏–≥–Ω–æ—Ä–∏—Ä—É–π "‚Äì", "N/A", –ø—É—Å—Ç—ã–µ, —Ç–µ–∫—Å—Ç)
   - –ù–µ —Å–ª—É–∂–µ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–∫–æ–Ω—Ç–∞–∫—Ç—ã, –∏—Ç–æ–≥–∏, –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–µ–∑ —Ü–µ–Ω)

3. –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û–õ–ï–ô:
   - unit: –∑–Ω–∞—á–µ–Ω–∏—è —á–∞—Å—Ç–æ –ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è (kg, pc, pkt, bottle, can, ml, l, g)
   - brand: –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –ó–ê–ì–õ–ê–í–ù–´–ú–ò –∏–ª–∏ Capitalized (–Ω–æ –Ω–µ unit)
   - size: —á–∏—Å–ª–∞ + –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è (200g, 1kg, 500ml)

–û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø:
- –ú–∞–∫—Å–∏–º—É–º 500 —Ç–æ–≤–∞—Ä–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
- –ù–µ –≤—Å—Ç–∞–≤–ª—è–π –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –≤–Ω—É—Ç—Ä–∏ JSON —Å—Ç—Ä–æ–∫
- –ù–∏–∫–∞–∫–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –≤ JSON

–ü–†–ò–ú–ï–† –í–ê–õ–ò–î–ù–û–ì–û JSON:
{{
  "table_analysis": {{
    "header_row": 10,
    "product_column": 1,
    "price_column": 3,
    "unit_column": 2,
    "brand_column": null,
    "size_column": null,
    "data_start_row": 12
  }},
  "extracted_products": [
    {{
      "row_index": 12,
      "product_name": "Basil Green Fresh",
      "brand": null,
      "price": 95000,
      "unit": "Kg",
      "size": null,
      "currency": "IDR",
      "source_supplier": null,
      "confidence": 0.95
    }}
  ]
}}

FALLBACK: –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å –Ω–∞–π—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏, –ø–æ–ø—Ä–æ–±—É–π –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç–æ–ª–±—Ü—ã –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê - —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ markdown:"""
        
        return prompt
    
    def _query_chatgpt(self, prompt: str) -> Optional[Dict]:
        """–ó–∞–ø—Ä–æ—Å –∫ ChatGPT API"""
        try:
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': 'gpt-4o',
                'messages': [
                    {
                        'role': 'system',
                        'content': '–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–æ–≤ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—é —Ç–æ–≤–∞—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–∞–±–ª–∏—Ü –ª—é–±–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –Ω–∞–π—Ç–∏ –í–°–ï —Ç–æ–≤–∞—Ä—ã —Å —Ü–µ–Ω–∞–º–∏ –∏ –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–≥–æ –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏ markdown. –ò–≥–Ω–æ—Ä–∏—Ä—É–π —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ —á–∏—Å–ª–æ–≤—ã—Ö —Ü–µ–Ω.'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'max_tokens': self.max_tokens,
                'temperature': 0,
                'response_format': {'type': 'json_object'}
            }
            
            logger.info("ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—É –Ω–∞ –∞–Ω–∞–ª–∏–∑ –≤ ChatGPT...")
            
            response = requests.post(
                'https://api.openai.com/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                tokens_used = result.get('usage', {}).get('total_tokens', 0)
                
                logger.info(f"‚úÖ ChatGPT –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª —Ç–∞–±–ª–∏—Ü—É, —Ç–æ–∫–µ–Ω–æ–≤: {tokens_used}")
                
                # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
                try:
                    parsed_response = json.loads(content)
                    return parsed_response
                except json.JSONDecodeError as e:
                    logger.error(f"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON –æ—Ç ChatGPT: {e}")
                    logger.debug(f"–û—Ç–≤–µ—Ç: {content}")
                    return None
            else:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ ChatGPT API: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ ChatGPT: {e}")
            return None
    
    def _parse_chatgpt_response(self, response: Dict, original_df: pd.DataFrame) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ ChatGPT –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        try:
            analysis = response.get('table_analysis', {})
            extracted_products = response.get('extracted_products', [])
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∏ –æ–±–æ–≥–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            validated_products = []
            
            for product in extracted_products:
                # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
                if not product.get('product_name') or not product.get('price'):
                    continue
                
                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º —Ñ–æ—Ä–º–∞—Ç
                validated_product = {
                    'original_name': product.get('product_name', ''),
                    'standardized_name': product.get('product_name', ''),
                    'brand': product.get('brand', ''),
                    'size': product.get('size', ''),
                    'price': self._clean_price(product.get('price', 0)),
                    'unit': product.get('unit', 'pcs'),
                    'currency': product.get('currency', 'IDR'),
                    'category': 'General',
                    'confidence': product.get('confidence', 0.9),
                    'row_index': product.get('row_index', 0),
                    'source_supplier': product.get('source_supplier', ''),
                    'extraction_method': 'ai_analysis'
                }
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
                if (validated_product['price'] > 0 and 
                    len(validated_product['original_name']) > 2):
                    validated_products.append(validated_product)
            
            result = {
                'analysis': analysis,
                'products': validated_products,
                'ai_extraction_stats': {
                    'total_found': len(extracted_products),
                    'validated_products': len(validated_products),
                    'confidence': sum(p['confidence'] for p in validated_products) / len(validated_products) if validated_products else 0,
                    'extraction_method': 'ai_powered'
                }
            }
            
            logger.info(f"üéØ AI –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ: {len(validated_products)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ {len(original_df)} —Å—Ç—Ä–æ–∫")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ ChatGPT: {e}")
            return None
    
    def extract_products_with_ai(self, df: pd.DataFrame, context: str = "") -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é AI
        """
        if not self.api_key:
            return {'error': 'OpenAI API key –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —á–µ—Ä–µ–∑ AI
        ai_result = self.analyze_table_structure(df, context)
        
        if ai_result and ai_result.get('products'):
            return {
                'file_type': 'ai_parsed',
                'supplier': {'name': 'AI_Extracted', 'confidence': 0.9},
                'products': ai_result['products'],
                'extraction_stats': ai_result.get('ai_extraction_stats', {}),
                'table_analysis': ai_result.get('analysis', {})
            }
        else:
            return {'error': 'AI –Ω–µ —Å–º–æ–≥ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É'}
    
    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ AI –ø–∞—Ä—Å–µ—Ä–∞"""
        return bool(self.api_key)