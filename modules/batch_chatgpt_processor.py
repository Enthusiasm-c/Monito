#!/usr/bin/env python3
"""
–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ ChatGPT
"""

import os
import json
import time
import asyncio
import logging
import requests
from typing import Dict, List, Any, Optional
from datetime import datetime
import re

logger = logging.getLogger(__name__)

class BatchChatGPTProcessor:
    """–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ ChatGPT"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.batch_size = 15  # –£–º–µ–Ω—å—à–∞–µ–º –¥–æ 15 —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.max_tokens = 4000  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ 20 —Ç–æ–≤–∞—Ä–æ–≤
        self.delay_between_requests = 0.2  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        self.assistant_id = "asst_MNWPJzAGJC7TrZ8LKTDnJLzr"  # ID —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        self.request_timeout = 120  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º timeout –¥–æ 120 —Å–µ–∫—É–Ω–¥ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        
    def split_products_into_batches(self, products: List[Dict], batch_size: int = None) -> List[List[Dict]]:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ –ø–∞–∫–µ—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        if batch_size is None:
            batch_size = self.batch_size
        
        batches = []
        for i in range(0, len(products), batch_size):
            batch = products[i:i + batch_size]
            batches.append(batch)
        
        logger.info(f"üì¶ –†–∞–∑–¥–µ–ª–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ {len(batches)} –ø–∞–∫–µ—Ç–æ–≤ –ø–æ {batch_size} —Ç–æ–≤–∞—Ä–æ–≤")
        for i, batch in enumerate(batches):
            logger.debug(f"  –ü–∞–∫–µ—Ç {i+1}: {len(batch)} —Ç–æ–≤–∞—Ä–æ–≤")
        return batches
    
    def estimate_tokens(self, text: str) -> int:
        """–ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤"""
        # –ü—Ä–∏–º–µ—Ä–Ω–æ 4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        # –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ
        return len(text) // 3
    
    def optimize_batch_size(self, products: List[Dict]) -> int:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ –ø–∞–∫–µ—Ç–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        if not products:
            return self.batch_size
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –Ω–∞–∑–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤
        avg_name_length = sum(len(p.get('original_name', '')) for p in products[:10]) / min(10, len(products))
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å: –º–µ–Ω—å—à–∏–µ –ø–∞–∫–µ—Ç—ã = –±—ã—Å—Ç—Ä–µ–µ –æ–±—Ä–∞–±–æ—Ç–∫–∞
        if avg_name_length > 50:  # –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            return 10  # –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –ø–∞–∫–µ—Ç—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã
        elif avg_name_length > 30:  # –î–ª–∏–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            return 12  # –ú–∞–ª–µ–Ω—å–∫–∏–µ –ø–∞–∫–µ—Ç—ã
        elif avg_name_length > 20:  # –°—Ä–µ–¥–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            return self.batch_size  # 15 —Ç–æ–≤–∞—Ä–æ–≤ (–±–∞–∑–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä)
        else:  # –ö–æ—Ä–æ—Ç–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            return min(self.batch_size + 5, 20)  # –î–æ 20 —Ç–æ–≤–∞—Ä–æ–≤ –º–∞–∫—Å–∏–º—É–º
    
    async def process_products_batch(self, products: List[Dict], supplier_name: str, batch_index: int = 0) -> Optional[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞ —Ç–æ–≤–∞—Ä–æ–≤ —á–µ—Ä–µ–∑ ChatGPT"""
        try:
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ChatGPT
            products_list = []
            for i, product in enumerate(products, 1):
                products_list.append(f"{i}. {product['original_name']} | {product['price']} {product.get('unit', 'pcs')}")
            
            products_text = "\n".join(products_list)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞
            estimated_tokens = self.estimate_tokens(products_text)
            logger.debug(f"üìè –ü–∞–∫–µ—Ç {batch_index + 1}: —Ä–∞–∑–º–µ—Ä {estimated_tokens} —Ç–æ–∫–µ–Ω–æ–≤ (–ª–∏–º–∏—Ç: {self.max_tokens * 0.7})")
            
            if estimated_tokens > self.max_tokens * 0.7:  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –¥–æ 70%
                logger.warning(f"‚ö†Ô∏è –ü–∞–∫–µ—Ç {batch_index + 1} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({estimated_tokens} —Ç–æ–∫–µ–Ω–æ–≤), –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ 2 —á–∞—Å—Ç–∏")
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Ä–∞–∑–¥–µ–ª—è–µ–º –ø–∞–∫–µ—Ç –ø–æ–ø–æ–ª–∞–º
                mid = len(products) // 2
                batch1 = await self.process_products_batch(products[:mid], supplier_name, batch_index)
                batch2 = await self.process_products_batch(products[mid:], supplier_name, batch_index)
                
                if batch1 and batch2:
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    combined_products = batch1.get('products', []) + batch2.get('products', [])
                    return {
                        'supplier': batch1.get('supplier', {}),
                        'products': combined_products,
                        'data_quality': batch1.get('data_quality', {})
                    }
                return batch1 or batch2
            
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            prompt = f"""–ë—ã—Å—Ç—Ä–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–π {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –≤ JSON.

–¢–û–í–ê–†–´:
{products_text}

JSON –û–¢–í–ï–¢:
{{
  "products": [
    {{
      "original_name": "–∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ",
      "standardized_name": "English Name",
      "brand": "Brand",
      "size": "—Ä–∞–∑–º–µ—Ä",
      "unit": "–µ–¥–∏–Ω–∏—Ü–∞", 
      "price": —Ü–µ–Ω–∞_—á–∏—Å–ª–æ–º,
      "currency": "IDR",
      "category": "–∫–∞—Ç–µ–≥–æ—Ä–∏—è"
    }}
  ]
}}

–ö–∞—Ç–µ–≥–æ—Ä–∏–∏: Food, Electronics, Clothing, Home, Health, Sports, Books, Auto, General
–ï–¥–∏–Ω–∏—Ü—ã: g, kg, ml, l, pcs, pack, box, can, bottle"""

            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }
            
            data_payload = {
                'model': 'gpt-4o-mini',  # –ò—Å–ø–æ–ª—å–∑—É–µ–º mini –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                'messages': [
                    {
                        'role': 'system',
                        'content': '–ë—ã—Å—Ç—Ä–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–π —Ç–æ–≤–∞—Ä—ã. –¢–æ–ª—å–∫–æ JSON.'
                    },
                    {
                        'role': 'user', 
                        'content': prompt
                    }
                ],
                'max_tokens': self.max_tokens,
                'temperature': 0,  # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
                'response_format': {'type': 'json_object'}
            }
            
            logger.info(f"üöÄ –û—Ç–ø—Ä–∞–≤–∫–∞ –ø–∞–∫–µ—Ç–∞ {batch_index + 1} —Å {len(products)} —Ç–æ–≤–∞—Ä–∞–º–∏ –≤ ChatGPT (—Ä–∞–∑–º–µ—Ä: {estimated_tokens} —Ç–æ–∫–µ–Ω–æ–≤)...")
            
            # –ë—ã—Å—Ç—Ä—ã–µ –ø–æ–ø—ã—Ç–∫–∏ —Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ —Ç–∞–π–º–∞—É—Ç–∞–º–∏
            max_retries = 2  # –£–º–µ–Ω—å—à–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
            for attempt in range(max_retries):
                try:
                    response = requests.post(
                        'https://api.openai.com/v1/chat/completions',
                        headers=headers,
                        json=data_payload,
                        timeout=self.request_timeout  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—ã–π timeout
                    )
                    break
                except requests.exceptions.Timeout:
                    wait_time = 2 + attempt  # –ë—ã—Å—Ç—Ä—ã–µ –ø–æ–≤—Ç–æ—Ä—ã: 2—Å, 3—Å
                    logger.warning(f"‚è∞ –ë—ã—Å—Ç—Ä—ã–π —Ç–∞–π–º–∞—É—Ç –ø–∞–∫–µ—Ç–∞ {batch_index + 1}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}. –û–∂–∏–¥–∞–Ω–∏–µ {wait_time}—Å...")
                    if attempt == max_retries - 1:
                        logger.error(f"‚ùå –ü–∞–∫–µ—Ç {batch_index + 1} –æ—Ç–±—Ä–æ—à–µ–Ω –ø–æ—Å–ª–µ {max_retries} –±—ã—Å—Ç—Ä—ã—Ö –ø–æ–ø—ã—Ç–æ–∫")
                        return None
                    time.sleep(wait_time)
                except Exception as e:
                    logger.error(f"‚ùå –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–∞ {batch_index + 1} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}): {type(e).__name__}: {e}")
                    if attempt == max_retries - 1:
                        logger.error(f"‚ùå –ü–∞–∫–µ—Ç {batch_index + 1} –æ—Ç–±—Ä–æ—à–µ–Ω –∏–∑-–∑–∞ —Å–µ—Ç–µ–≤–æ–π –æ—à–∏–±–∫–∏")
                        return None
                    time.sleep(1)  # –ë—ã—Å—Ç—Ä–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
            
            logger.debug(f"üì° HTTP –æ—Ç–≤–µ—Ç –ø–∞–∫–µ—Ç–∞ {batch_index + 1}: –∫–æ–¥ {response.status_code}")
            
            if response.status_code == 200:
                try:
                    result = response.json()
                    content = result['choices'][0]['message']['content']
                    tokens_used = result.get('usage', {}).get('total_tokens', 0)
                    logger.debug(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –¥–ª—è –ø–∞–∫–µ—Ç–∞ {batch_index + 1}: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤, {tokens_used} —Ç–æ–∫–µ–Ω–æ–≤")
                except Exception as e:
                    logger.error(f"‚ùå –û–®–ò–ë–ö–ê –ü–ê–†–°–ò–ù–ì–ê JSON –æ—Ç–≤–µ—Ç–∞ API –¥–ª—è –ø–∞–∫–µ—Ç–∞ {batch_index + 1}: {e}")
                    return None
                
                # –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
                content = self.clean_chatgpt_response(content)
                
                # –ü–∞—Ä—Å–∏–Ω–≥ JSON —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
                logger.debug(f"üîç –ü–∞—Ä—Å–∏–Ω–≥ JSON –æ—Ç–≤–µ—Ç–∞ –ø–∞–∫–µ—Ç–∞ {batch_index + 1}...")
                try:
                    parsed_data = json.loads(content)
                    logger.debug(f"‚úÖ JSON —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω –¥–ª—è –ø–∞–∫–µ—Ç–∞ {batch_index + 1}")
                    
                    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
                    if 'products' in parsed_data:
                        processed_products = []
                        
                        invalid_products = 0
                        for i, product in enumerate(parsed_data['products']):
                            # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
                            if not product.get('standardized_name') and not product.get('name'):
                                invalid_products += 1
                                logger.warning(f"‚ö†Ô∏è –ü–∞–∫–µ—Ç {batch_index + 1}, —Ç–æ–≤–∞—Ä {i+1}: –ë–ï–ó –ù–ê–ó–í–ê–ù–ò–Ø - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º. –î–∞–Ω–Ω—ã–µ: {product}")
                                continue
                            
                            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –ø–æ–ª–µ–π
                            standardized_product = {
                                'original_name': product.get('original_name', products[i].get('original_name', '') if i < len(products) else ''),
                                'standardized_name': product.get('standardized_name') or product.get('name', ''),
                                'brand': product.get('brand', 'Unknown'),
                                'size': product.get('size', ''),
                                'unit': product.get('unit', 'pcs'),
                                'price': product.get('price', products[i].get('price', 0) if i < len(products) else 0),
                                'currency': product.get('currency', 'IDR'),
                                'category': product.get('category', 'General'),
                                'confidence': 0.95  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö ChatGPT —Ç–æ–≤–∞—Ä–æ–≤
                            }
                            
                            processed_products.append(standardized_product)
                        
                        parsed_data['products'] = processed_products
                        processed_count = len(processed_products)
                        input_count = len(products)
                        loss_count = input_count - processed_count
                        
                        if invalid_products > 0:
                            logger.warning(f"‚ö†Ô∏è –ü–∞–∫–µ—Ç {batch_index + 1}: {invalid_products} —Ç–æ–≤–∞—Ä–æ–≤ –ë–ï–ó –ù–ê–ó–í–ê–ù–ò–ô –æ—Ç–±—Ä–æ—à–µ–Ω–æ")
                        
                        if loss_count > 0:
                            logger.warning(f"‚ö†Ô∏è –ü–∞–∫–µ—Ç {batch_index + 1}: –ü–û–¢–ï–†–Ø {loss_count} —Ç–æ–≤–∞—Ä–æ–≤ ({loss_count/input_count:.1%})")
                        
                        logger.info(f"‚úÖ –ü–∞–∫–µ—Ç {batch_index + 1}: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count}/{input_count} —Ç–æ–≤–∞—Ä–æ–≤ (–ø–æ—Ç–µ—Ä–∏: {loss_count}), —Ç–æ–∫–µ–Ω–æ–≤: {tokens_used}")
                        
                        return parsed_data
                    else:
                        logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ù–û: –ù–µ—Ç –ø–æ–ª—è 'products' –≤ –æ—Ç–≤–µ—Ç–µ –ø–∞–∫–µ—Ç–∞ {batch_index + 1}")
                        logger.error(f"üìã –ü–æ–ª—É—á–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: {list(parsed_data.keys()) if isinstance(parsed_data, dict) else type(parsed_data)}")
                        return None
                    
                except json.JSONDecodeError as e:
                    logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ù–û: –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON –≤ –ø–∞–∫–µ—Ç–µ {batch_index + 1}: {e}")
                    logger.error(f"üìã –ü—Ä–æ–±–ª–µ–º–Ω—ã–π –æ—Ç–≤–µ—Ç (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {content[:500]}...")
                    logger.error(f"üìã –†–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                    return None
                    
            else:
                logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ù–û: –û—à–∏–±–∫–∞ ChatGPT API –¥–ª—è –ø–∞–∫–µ—Ç–∞ {batch_index + 1}")
                logger.error(f"üì° HTTP –∫–æ–¥: {response.status_code}")
                logger.error(f"üìã –û—Ç–≤–µ—Ç API: {response.text[:500]}...")
                
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –æ—à–∏–±–æ–∫
                if response.status_code == 429:
                    logger.error(f"üö´ Rate limiting - —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤")
                elif response.status_code == 400:
                    logger.error(f"üö´ –ù–µ–≤–µ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å - –≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤")
                elif response.status_code == 401:
                    logger.error(f"üö´ –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ API –∫–ª—é—á")
                elif response.status_code >= 500:
                    logger.error(f"üö´ –°–µ—Ä–≤–µ—Ä–Ω–∞—è –æ—à–∏–±–∫–∞ OpenAI")
                
                return None
                
        except Exception as e:
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ù–û: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞–∫–µ—Ç–∞ {batch_index + 1}: {type(e).__name__}: {e}")
            import traceback
            logger.error(f"üìã –°—Ç–µ–∫ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
            return None
    
    async def _process_batch_with_timing(self, batch: List[Dict], supplier_name: str, batch_index: int) -> Optional[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–∫–µ—Ç–∞ —Å –∏–∑–º–µ—Ä–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        start_time = time.time()
        logger.info(f"üîÑ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–∫–µ—Ç–∞ {batch_index + 1}/{batch_index + 1} ({len(batch)} —Ç–æ–≤–∞—Ä–æ–≤)...")
        
        try:
            result = await self.process_products_batch(batch, supplier_name, batch_index)
            processing_time = time.time() - start_time
            
            if result:
                result['processing_time'] = processing_time
                return result
            else:
                logger.warning(f"‚ö†Ô∏è –ü–∞–∫–µ—Ç {batch_index + 1} –≤–µ—Ä–Ω—É–ª None –∑–∞ {processing_time:.1f}—Å")
                return None
                
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–º –ø–∞–∫–µ—Ç–µ {batch_index + 1} –∑–∞ {processing_time:.1f}—Å: {e}")
            raise e
    
    def clean_chatgpt_response(self, content: str) -> str:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ ChatGPT"""
        content = content.strip()
        
        # –£–¥–∞–ª–µ–Ω–∏–µ markdown –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞
        if content.startswith('```json'):
            content = content[7:]
        elif content.startswith('```'):
            content = content[3:]
            
        if content.endswith('```'):
            content = content[:-3]
        
        content = content.strip()
        
        # –ü–æ–∏—Å–∫ JSON –±–ª–æ–∫–∞ –≤ —Ç–µ–∫—Å—Ç–µ
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            content = json_match.group(0)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
        lines = content.split('\n')
        clean_lines = []
        for line in lines:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
            if not line.strip().startswith('//') and not line.strip().startswith('#'):
                clean_lines.append(line)
        
        return '\n'.join(clean_lines)
    
    async def process_all_products(self, products: List[Dict], supplier_name: str) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ –ø–∞–∫–µ—Ç—ã"""
        try:
            if not products:
                return {'error': '–ù–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏'}
            
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞
            optimal_batch_size = self.optimize_batch_size(products)
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –ø–∞–∫–µ—Ç—ã
            batches = self.split_products_into_batches(products, optimal_batch_size)
            
            logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞–∫–µ—Ç–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –≤ {len(batches)} –ø–∞–∫–µ—Ç–∞—Ö")
            logger.info(f"üìä –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞: {optimal_batch_size} —Ç–æ–≤–∞—Ä–æ–≤")
            
            all_processed_products = []
            successful_batches = 0
            failed_batches = 0
            total_tokens = 0
            failed_batch_details = []
            
            # –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –ü–ê–ö–ï–¢–û–í –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏
            logger.info(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(batches)} –ø–∞–∫–µ—Ç–æ–≤...")
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            batch_tasks = []
            for i, batch in enumerate(batches):
                task = asyncio.create_task(
                    self._process_batch_with_timing(batch, supplier_name, i)
                )
                batch_tasks.append(task)
                
                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—É—Å–∫–æ–º –∑–∞–¥–∞—á —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∑–∏—Ç—å API
                if i > 0:
                    await asyncio.sleep(self.delay_between_requests)
            
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –ø–∞–∫–µ—Ç–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            logger.info(f"‚è≥ –û–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è {len(batch_tasks)} –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á...")
            batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for i, result in enumerate(batch_results):
                if isinstance(result, Exception):
                    failed_batches += 1
                    failure_reason = f"{type(result).__name__}: {result}"
                    failed_batch_details.append(f"–ü–∞–∫–µ—Ç {i + 1}: {failure_reason}")
                    logger.error(f"‚ùå –ü–∞–∫–µ—Ç {i + 1} –ü–†–û–í–ê–õ–ï–ù: {failure_reason}")
                elif result and 'products' in result:
                    batch_products = result['products']
                    all_processed_products.extend(batch_products)
                    successful_batches += 1
                    
                    # –£—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã
                    total_tokens += self.estimate_tokens(str(result))
                    
                    batch_time = result.get('processing_time', 0)
                    logger.info(f"‚úÖ –ü–∞–∫–µ—Ç {i + 1} –£–°–ü–ï–®–ù–û: {len(batch_products)} —Ç–æ–≤–∞—Ä–æ–≤ –∑–∞ {batch_time:.1f}—Å")
                else:
                    failed_batches += 1
                    failure_reason = "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–ª–∏ –Ω–µ—Ç products –≤ –æ—Ç–≤–µ—Ç–µ"
                    failed_batch_details.append(f"–ü–∞–∫–µ—Ç {i + 1}: {failure_reason}")
                    logger.error(f"‚ùå –ü–∞–∫–µ—Ç {i + 1} –ü–†–û–í–ê–õ–ï–ù: {failure_reason}")
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Ç–µ—Ä—å
            total_input_products = len(products)
            total_output_products = len(all_processed_products)
            loss_count = total_input_products - total_output_products
            loss_percentage = (loss_count / total_input_products * 100) if total_input_products > 0 else 0
            
            logger.info(f"üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–ê–ö–ï–¢–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–ò:")
            logger.info(f"   üì¶ –£—Å–ø–µ—à–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤: {successful_batches}/{len(batches)} ({successful_batches/len(batches)*100:.1f}%)")
            logger.info(f"   ‚ùå –ü—Ä–æ–≤–∞–ª–∏–≤—à–∏—Ö—Å—è –ø–∞–∫–µ—Ç–æ–≤: {failed_batches}/{len(batches)} ({failed_batches/len(batches)*100:.1f}%)")
            logger.info(f"   üìù –¢–æ–≤–∞—Ä–æ–≤ –Ω–∞ –≤—Ö–æ–¥–µ: {total_input_products}")
            logger.info(f"   ‚úÖ –¢–æ–≤–∞—Ä–æ–≤ –Ω–∞ –≤—ã—Ö–æ–¥–µ: {total_output_products}")
            logger.info(f"   üìâ –ü–û–¢–ï–†–ò: {loss_count} —Ç–æ–≤–∞—Ä–æ–≤ ({loss_percentage:.1f}%)")
            logger.info(f"   ü™ô –û–±—â–∏–π —Ä–∞—Å—Ö–æ–¥ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens}")
            
            if failed_batch_details:
                logger.warning(f"üîç –î–ï–¢–ê–õ–ò –ü–†–û–í–ê–õ–û–í:")
                for detail in failed_batch_details:
                    logger.warning(f"   ‚Ä¢ {detail}")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if all_processed_products:
                result = {
                    'supplier': {
                        'name': supplier_name,
                        'confidence': 0.9
                    },
                    'products': all_processed_products,
                    'data_quality': {
                        'extraction_confidence': successful_batches / len(batches),
                        'source_clarity': 'high' if successful_batches > len(batches) * 0.8 else 'medium',
                        'potential_errors': [] if successful_batches == len(batches) else [f'–ù–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(batches) - successful_batches} –ø–∞–∫–µ—Ç–æ–≤']
                    },
                    'processing_stats': {
                        'total_input_products': len(products),
                        'total_output_products': len(all_processed_products),
                        'successful_batches': successful_batches,
                        'total_batches': len(batches),
                        'estimated_tokens': total_tokens,
                        'success_rate': len(all_processed_products) / len(products) if products else 0
                    }
                }
                
                logger.info(f"üéâ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(all_processed_products)}/{len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
                return result
            else:
                # Fallback: –µ—Å–ª–∏ ChatGPT –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
                logger.warning("üîÑ ChatGPT –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
                fallback_products = []
                for product in products:
                    fallback_product = {
                        'original_name': product.get('original_name', ''),
                        'standardized_name': product.get('original_name', ''),
                        'brand': 'unknown',
                        'price': product.get('price', 0),
                        'unit': product.get('unit', 'pcs'),
                        'category': 'general',
                        'confidence': 0.6  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –±–µ–∑ ChatGPT
                    }
                    fallback_products.append(fallback_product)
                
                return {
                    'supplier': {'name': supplier_name, 'confidence': 0.7},
                    'products': fallback_products,
                    'data_quality': {
                        'extraction_confidence': 0.6,
                        'source_clarity': 'low',
                        'potential_errors': ['–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –±–µ–∑ ChatGPT - –±–∞–∑–æ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ']
                    },
                    'processing_stats': {
                        'total_input_products': len(products),
                        'total_output_products': len(fallback_products),
                        'successful_batches': 0,
                        'total_batches': len(batches),
                        'estimated_tokens': 0,
                        'success_rate': 1.0,
                        'fallback_used': True
                    }
                }
                
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            return {'error': str(e)}