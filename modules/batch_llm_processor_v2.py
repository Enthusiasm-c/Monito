#!/usr/bin/env python3
"""
Batch LLM Processor V2 –¥–ª—è MON-004 - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
–û—Å–Ω–æ–≤–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:
- JSONL batch —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –ø–µ—Ä–µ–¥–∞—á–∏
- RapidFuzz pre-filtering –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤
- Intelligent token optimization
- 30% —ç–∫–æ–Ω–æ–º–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏ OpenAI API
"""

import os
import json
import time
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path
import openai

logger = logging.getLogger(__name__)

@dataclass
class LLMStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è MON-004"""
    input_products: int = 0
    filtered_products: int = 0
    tokens_input: int = 0
    tokens_output: int = 0
    tokens_saved: int = 0
    api_calls: int = 0
    processing_time_ms: int = 0
    cost_usd: float = 0.0
    cost_saved_usd: float = 0.0

class BatchLLMProcessorV2:
    """
    Batch LLM Processor V2 –¥–ª—è MON-004 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    
    –ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:
    - üìÑ JSONL —Ñ–æ—Ä–º–∞—Ç –¥–ª—è batch –æ–±—Ä–∞–±–æ—Ç–∫–∏
    - üîç RapidFuzz pre-filtering (–∏–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã)
    - üß† Intelligent token optimization
    - üí∞ 30% —ç–∫–æ–Ω–æ–º–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏
    """
    
    def __init__(self, openai_api_key: str = None):
        # OpenAI API
        self.openai_api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
        if self.openai_api_key:
            openai.api_key = self.openai_api_key
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = LLMStats()
        
        # –ö—ç—à –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        self.product_cache = {}
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self.similarity_threshold = 0.85  # RapidFuzz –ø–æ—Ä–æ–≥
        self.max_batch_size = 50  # –ú–∞–∫—Å–∏–º—É–º —Ç–æ–≤–∞—Ä–æ–≤ –≤ batch
        self.max_tokens_per_request = 3500  # –õ–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        self._check_dependencies()
        
        logger.info("‚úÖ BatchLLMProcessorV2 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å MON-004 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏")
    
    def _check_dependencies(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π MON-004"""
        self.rapidfuzz_available = False
        self.jsonlines_available = False
        
        try:
            import rapidfuzz
            self.rapidfuzz_available = True
            logger.info("‚úÖ RapidFuzz –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è pre-filtering")
        except ImportError:
            logger.warning("‚ö†Ô∏è RapidFuzz –Ω–µ –Ω–∞–π–¥–µ–Ω, –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞")
        
        try:
            import jsonlines
            self.jsonlines_available = True
            logger.info("‚úÖ jsonlines –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è JSONL —Ñ–æ—Ä–º–∞—Ç–∞")
        except ImportError:
            logger.warning("‚ö†Ô∏è jsonlines –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π JSON")
    
    def standardize_products_batch(self, products: List[Dict[str, Any]], 
                                 supplier_info: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        MON-004: Batch —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è —Ç–æ–≤–∞—Ä–æ–≤ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
        
        Args:
            products: –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
            supplier_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Å—Ç–∞–≤—â–∏–∫–µ
        
        Returns:
            Dict —Å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ç–æ–≤–∞—Ä–∞–º–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        start_time = time.time()
        
        try:
            logger.info(f"üöÄ MON-004: –ù–∞—á–∏–Ω–∞–µ–º batch —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
            
            # –°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self.stats = LLMStats()
            self.stats.input_products = len(products)
            
            if not self.openai_api_key:
                logger.error("‚ùå OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return self._create_error_result("OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            
            if not products:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                return self._create_empty_result()
            
            # –®–∞–≥ 1: RapidFuzz pre-filtering (MON-004.1)
            filtered_products = self._rapidfuzz_prefilter(products)
            
            # –®–∞–≥ 2: –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –±–∞—Ç—á–∏ (MON-004.2)
            batches = self._create_optimal_batches(filtered_products)
            
            # –®–∞–≥ 3: JSONL batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ (MON-004.3)
            standardized_products = []
            for batch_idx, batch in enumerate(batches):
                logger.info(f"üì¶ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º batch {batch_idx + 1}/{len(batches)}: {len(batch)} —Ç–æ–≤–∞—Ä–æ–≤")
                
                batch_result = self._process_batch_jsonl(batch, supplier_info)
                if batch_result:
                    standardized_products.extend(batch_result)
            
            # –®–∞–≥ 4: –î–æ–±–∞–≤–ª—è–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            standardized_products.extend(self._get_cached_results())
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_time = int((time.time() - start_time) * 1000)
            self.stats.processing_time_ms = total_time
            
            # –†–∞—Å—á–µ—Ç —ç–∫–æ–Ω–æ–º–∏–∏
            cost_savings = self._calculate_cost_savings()
            
            result = {
                'success': True,
                'standardized_products': standardized_products,
                'total_products': len(standardized_products),
                'supplier': supplier_info or {'name': 'Unknown'},
                'processing_stats': {
                    'input_products': self.stats.input_products,
                    'filtered_products': self.stats.filtered_products,
                    'tokens_input': self.stats.tokens_input,
                    'tokens_output': self.stats.tokens_output,
                    'tokens_saved': self.stats.tokens_saved,
                    'api_calls': self.stats.api_calls,
                    'processing_time_ms': self.stats.processing_time_ms,
                    'cost_usd': self.stats.cost_usd,
                    'cost_saved_usd': self.stats.cost_saved_usd,
                    'cost_savings_percent': cost_savings.get('savings_percent', 0),
                    'method': 'BatchLLMProcessorV2_MON004'
                },
                'optimization_results': cost_savings
            }
            
            logger.info(f"‚úÖ MON-004 COMPLETED: {len(standardized_products)} —Ç–æ–≤–∞—Ä–æ–≤ –∑–∞ {total_time}ms")
            logger.info(f"   üí∞ –≠–∫–æ–Ω–æ–º–∏—è: {cost_savings.get('savings_percent', 0):.1f}% "
                       f"(${cost_savings.get('cost_saved', 0):.3f})")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ batch —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏: {e}")
            return self._create_error_result(str(e))
    
    def _rapidfuzz_prefilter(self, products: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        MON-004.1: RapidFuzz pre-filtering –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        –¶–µ–ª—å: –°–Ω–∏–∂–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ 20-30% —á–µ—Ä–µ–∑ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é
        """
        if not self.rapidfuzz_available:
            logger.info("üìù RapidFuzz –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º pre-filtering")
            self.stats.filtered_products = len(products)
            return products
        
        start_time = time.time()
        
        try:
            from rapidfuzz import fuzz, process
            
            logger.info(f"üîç MON-004.1: RapidFuzz pre-filtering —Å –ø–æ—Ä–æ–≥–æ–º {self.similarity_threshold}")
            
            unique_products = []
            cached_products = []
            seen_names = []
            
            for product in products:
                original_name = product.get('original_name', '').strip().lower()
                
                if not original_name:
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ—Ö–æ–∂–µ—Å—Ç—å —Å —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏
                if seen_names:
                    best_match = process.extractOne(
                        original_name, 
                        seen_names, 
                        scorer=fuzz.ratio,
                        score_cutoff=self.similarity_threshold * 100
                    )
                    
                    if best_match:
                        # –ù–∞–π–¥–µ–Ω –ø–æ—Ö–æ–∂–∏–π —Ç–æ–≤–∞—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à
                        cached_name = best_match[0]
                        if cached_name in self.product_cache:
                            cached_product = self.product_cache[cached_name].copy()
                            cached_product['original_name'] = product.get('original_name', '')
                            cached_product['price'] = product.get('price', 0)
                            cached_products.append(cached_product)
                            continue
                
                # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ç–æ–≤–∞—Ä, –¥–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—Ä–∞–±–æ—Ç–∫—É
                unique_products.append(product)
                seen_names.append(original_name)
            
            filter_time = int((time.time() - start_time) * 1000)
            
            # –†–∞—Å—á–µ—Ç —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
            original_count = len(products)
            filtered_count = len(unique_products)
            cached_count = len(cached_products)
            
            self.stats.filtered_products = filtered_count
            tokens_saved = (original_count - filtered_count) * 50  # –ü—Ä–∏–º–µ—Ä–Ω–æ 50 —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ —Ç–æ–≤–∞—Ä
            self.stats.tokens_saved += tokens_saved
            
            logger.info(f"‚úÖ Pre-filtering –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {filter_time}ms:")
            logger.info(f"   üì¶ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {filtered_count}")
            logger.info(f"   üíæ –ò–∑ –∫—ç—à–∞: {cached_count}")
            logger.info(f"   üí∞ –¢–æ–∫–µ–Ω–æ–≤ —Å—ç–∫–æ–Ω–æ–º–ª–µ–Ω–æ: {tokens_saved}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–æ–∑–∂–µ
            self._cached_results = cached_products
            
            return unique_products
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ RapidFuzz pre-filtering: {e}")
            self.stats.filtered_products = len(products)
            return products
    
    def _create_optimal_batches(self, products: List[Dict[str, Any]]) -> List[List[Dict[str, Any]]]:
        """
        MON-004.2: –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –±–∞—Ç—á–µ–π –ø–æ —Ç–æ–∫–µ–Ω–∞–º
        –¶–µ–ª—å: –ú–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API –ª–∏–º–∏—Ç–æ–≤
        """
        logger.info(f"üì¶ MON-004.2: –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –±–∞—Ç—á–∏ (max {self.max_batch_size} —Ç–æ–≤–∞—Ä–æ–≤)")
        
        batches = []
        current_batch = []
        current_tokens = 0
        base_prompt_tokens = 200  # –ë–∞–∑–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã –ø—Ä–æ–º–ø—Ç–∞
        
        for product in products:
            # –û—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ (–∏–º—è + –æ–ø–∏—Å–∞–Ω–∏–µ)
            product_name = product.get('original_name', '')
            estimated_tokens = len(product_name.split()) * 1.3 + 20  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç—ã
            if (len(current_batch) >= self.max_batch_size or 
                current_tokens + estimated_tokens > self.max_tokens_per_request - base_prompt_tokens):
                
                if current_batch:
                    batches.append(current_batch)
                    current_batch = []
                    current_tokens = 0
            
            current_batch.append(product)
            current_tokens += estimated_tokens
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π batch
        if current_batch:
            batches.append(current_batch)
        
        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(batches)} –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –±–∞—Ç—á–µ–π")
        return batches
    
    def _process_batch_jsonl(self, batch: List[Dict[str, Any]], 
                           supplier_info: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """
        MON-004.3: –û–±—Ä–∞–±–æ—Ç–∫–∞ batch —á–µ—Ä–µ–∑ JSONL —Ñ–æ—Ä–º–∞—Ç
        –¶–µ–ª—å: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞
        """
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ JSONL –¥–∞–Ω–Ω—ã—Ö
            jsonl_data = self._prepare_jsonl_batch(batch, supplier_info)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
            prompt = self._create_optimized_prompt(jsonl_data, supplier_info)
            
            # API –∑–∞–ø—Ä–æ—Å
            response = self._make_optimized_api_call(prompt)
            
            # –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            standardized_products = self._parse_jsonl_response(response, batch)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞
            self._update_product_cache(batch, standardized_products)
            
            return standardized_products
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ JSONL batch: {e}")
            return []
    
    def _prepare_jsonl_batch(self, batch: List[Dict[str, Any]], 
                           supplier_info: Dict[str, Any] = None) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ JSONL —Ñ–æ—Ä–º–∞—Ç–µ"""
        try:
            if self.jsonlines_available:
                import jsonlines
                import io
                
                output = io.StringIO()
                with jsonlines.Writer(output) as writer:
                    for i, product in enumerate(batch):
                        item = {
                            'id': i,
                            'name': product.get('original_name', ''),
                            'price': product.get('price', 0),
                            'unit': product.get('unit', 'pcs')
                        }
                        writer.write(item)
                
                return output.getvalue()
            else:
                # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π JSON
                items = []
                for i, product in enumerate(batch):
                    items.append({
                        'id': i,
                        'name': product.get('original_name', ''),
                        'price': product.get('price', 0),
                        'unit': product.get('unit', 'pcs')
                    })
                return '\n'.join(json.dumps(item) for item in items)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ JSONL: {e}")
            return ""
    
    def _create_optimized_prompt(self, jsonl_data: str, supplier_info: Dict[str, Any] = None) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤"""
        supplier_name = supplier_info.get('name', 'Unknown') if supplier_info else 'Unknown'
        
        # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
        prompt = f"""Standardize product names from {supplier_name}. Return JSONL format only.

Input JSONL:
{jsonl_data}

Rules:
- Clean & standardize names (remove extra spaces, fix typos)
- Detect brand, size, category
- Keep original structure
- No explanations, only JSONL output

Expected output format per line:
{{"id": 0, "standardized_name": "Product Name", "brand": "Brand", "size": "100g", "category": "food", "confidence": 0.9}}"""

        return prompt
    
    def _make_optimized_api_call(self, prompt: str) -> str:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π API –≤—ã–∑–æ–≤"""
        try:
            # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤
            estimated_input_tokens = len(prompt.split()) * 1.3
            self.stats.tokens_input += int(estimated_input_tokens)
            
            start_time = time.time()
            
            response = openai.chat.completions.create(
                model="gpt-3.5-turbo",  # –ë–æ–ª–µ–µ –¥–µ—à–µ–≤–∞—è –º–æ–¥–µ–ª—å
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                response_format={"type": "text"}  # –û–∂–∏–¥–∞–µ–º —Ç–µ–∫—Å—Ç
            )
            
            api_time = int((time.time() - start_time) * 1000)
            self.stats.api_calls += 1
            
            # –ü–æ–¥—Å—á–µ—Ç –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
            response_text = response.choices[0].message.content
            estimated_output_tokens = len(response_text.split()) * 1.3
            self.stats.tokens_output += int(estimated_output_tokens)
            
            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏ (–ø—Ä–∏–º–µ—Ä–Ω—ã–µ —Ü–µ–Ω—ã GPT-3.5-turbo)
            input_cost = (self.stats.tokens_input / 1000) * 0.0015  # $0.0015 per 1K input tokens
            output_cost = (self.stats.tokens_output / 1000) * 0.002  # $0.002 per 1K output tokens
            self.stats.cost_usd = input_cost + output_cost
            
            logger.debug(f"ü§ñ API –≤—ã–∑–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {api_time}ms: "
                        f"{int(estimated_input_tokens)} ‚Üí {int(estimated_output_tokens)} —Ç–æ–∫–µ–Ω–æ–≤")
            
            return response_text
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ API –≤—ã–∑–æ–≤–∞: {e}")
            return ""
    
    def _parse_jsonl_response(self, response_text: str, 
                            original_batch: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ JSONL –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM"""
        try:
            standardized_products = []
            
            for line in response_text.strip().split('\n'):
                if not line.strip():
                    continue
                
                try:
                    parsed = json.loads(line)
                    product_id = parsed.get('id', 0)
                    
                    # –ù–∞—Ö–æ–¥–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–æ–≤–∞—Ä
                    if product_id < len(original_batch):
                        original_product = original_batch[product_id]
                        
                        standardized_product = {
                            'original_name': original_product.get('original_name', ''),
                            'standardized_name': parsed.get('standardized_name', ''),
                            'brand': parsed.get('brand', 'unknown'),
                            'size': parsed.get('size', 'unknown'),
                            'category': parsed.get('category', 'general'),
                            'price': original_product.get('price', 0),
                            'unit': original_product.get('unit', 'pcs'),
                            'currency': original_product.get('currency', 'USD'),
                            'confidence': parsed.get('confidence', 0.8)
                        }
                        
                        standardized_products.append(standardized_product)
                
                except json.JSONDecodeError as e:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–∞—Ä—Å–∏—Ç—å —Å—Ç—Ä–æ–∫—É JSONL: {line}")
                    continue
            
            logger.info(f"‚úÖ –°–ø–∞—Ä—Å–µ–Ω–æ {len(standardized_products)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ JSONL")
            return standardized_products
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSONL: {e}")
            return []
    
    def _update_product_cache(self, original_batch: List[Dict[str, Any]], 
                            standardized_batch: List[Dict[str, Any]]):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞ –¥–ª—è RapidFuzz"""
        try:
            for original, standardized in zip(original_batch, standardized_batch):
                cache_key = original.get('original_name', '').strip().lower()
                if cache_key:
                    self.product_cache[cache_key] = standardized
            
            logger.debug(f"üíæ –ö—ç—à –æ–±–Ω–æ–≤–ª–µ–Ω: {len(self.product_cache)} —Ç–æ–≤–∞—Ä–æ–≤")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫—ç—à–∞: {e}")
    
    def _get_cached_results(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        return getattr(self, '_cached_results', [])
    
    def _calculate_cost_savings(self) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç —ç–∫–æ–Ω–æ–º–∏–∏ –æ—Ç MON-004 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π"""
        try:
            # –†–∞—Å—á–µ—Ç —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –±–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
            theoretical_tokens = self.stats.input_products * 60  # –ë–µ–∑ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
            theoretical_cost = (theoretical_tokens / 1000) * 0.0015
            
            actual_cost = self.stats.cost_usd
            cost_saved = theoretical_cost - actual_cost
            savings_percent = (cost_saved / theoretical_cost) * 100 if theoretical_cost > 0 else 0
            
            self.stats.cost_saved_usd = cost_saved
            
            return {
                'theoretical_tokens': theoretical_tokens,
                'actual_tokens': self.stats.tokens_input + self.stats.tokens_output,
                'tokens_saved': self.stats.tokens_saved + (theoretical_tokens - self.stats.tokens_input),
                'theoretical_cost': theoretical_cost,
                'actual_cost': actual_cost,
                'cost_saved': cost_saved,
                'savings_percent': savings_percent,
                'optimization_methods': [
                    'RapidFuzz pre-filtering',
                    'JSONL batch format',
                    'Optimized prompts',
                    'GPT-3.5-turbo model'
                ]
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —ç–∫–æ–Ω–æ–º–∏–∏: {e}")
            return {'savings_percent': 0}
    
    def _create_empty_result(self) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        return {
            'success': True,
            'standardized_products': [],
            'total_products': 0,
            'processing_stats': {
                'method': 'BatchLLMProcessorV2_empty'
            }
        }
    
    def _create_error_result(self, error_message: str) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å –æ—à–∏–±–∫–æ–π"""
        return {
            'success': False,
            'error': error_message,
            'standardized_products': [],
            'total_products': 0,
            'processing_stats': {
                'method': 'BatchLLMProcessorV2_error'
            }
        }
    
    def get_optimization_report(self) -> Dict[str, Any]:
        """–û—Ç—á–µ—Ç –æ–± –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ö MON-004"""
        return {
            'mon_004_optimizations': {
                'rapidfuzz_prefiltering': self.rapidfuzz_available,
                'jsonl_format': self.jsonlines_available,
                'similarity_threshold': self.similarity_threshold,
                'max_batch_size': self.max_batch_size,
                'max_tokens_per_request': self.max_tokens_per_request
            },
            'performance_stats': {
                'input_products': self.stats.input_products,
                'filtered_products': self.stats.filtered_products,
                'tokens_input': self.stats.tokens_input,
                'tokens_output': self.stats.tokens_output,
                'tokens_saved': self.stats.tokens_saved,
                'api_calls': self.stats.api_calls,
                'cost_usd': self.stats.cost_usd,
                'cost_saved_usd': self.stats.cost_saved_usd
            },
            'version': 'BatchLLMProcessorV2_MON004'
        }


# Backward compatibility wrapper
class BatchChatGPTProcessor(BatchLLMProcessorV2):
    """
    –û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä—ã–º API
    –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞ –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é —Å MON-004 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
    """
    
    def __init__(self, openai_api_key: str = None):
        super().__init__(openai_api_key)
        logger.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è BatchChatGPTProcessor V2 —Å MON-004 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏") 