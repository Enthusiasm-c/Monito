"""
=============================================================================
MONITO DATA MIGRATION SCRIPT
=============================================================================
–í–µ—Ä—Å–∏—è: 3.0
–¶–µ–ª—å: –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ legacy —Å–∏—Å—Ç–µ–º—ã –≤ unified —Å–∏—Å—Ç–µ–º—É
=============================================================================
"""

import os
import sys
import logging
import argparse
import json
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent.parent))

from modules.adapters.legacy_integration_adapter import LegacyIntegrationAdapter
from utils.logger import get_logger

logger = get_logger(__name__)

class DataMigrationScript:
    """
    –°–∫—Ä–∏–ø—Ç –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ legacy —Å–∏—Å—Ç–µ–º—ã –≤ unified —Å–∏—Å—Ç–µ–º—É
    """
    
    def __init__(self, config_file: str = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞
        
        Args:
            config_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        """
        self.config = self._load_config(config_file)
        self.integration_adapter = None
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self._setup_logging()
        
        logger.info("DataMigrationScript initialized")
    
    def _load_config(self, config_file: str = None) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–∏–≥—Ä–∞—Ü–∏–∏"""
        default_config = {
            'database': {
                'url': os.getenv('DATABASE_URL', 'sqlite:///monito_unified.db'),
                'backup_before_migration': True
            },
            'migration': {
                'data_directory': './data/legacy',
                'file_patterns': ['*.xlsx', '*.xls', '*.pdf'],
                'batch_size': 100,
                'auto_merge_duplicates': True,
                'validation_enabled': True
            },
            'logging': {
                'level': 'INFO',
                'file': './logs/migration.log'
            },
            'output': {
                'report_file': './reports/migration_report.json',
                'create_backup': True
            }
        }
        
        if config_file and Path(config_file).exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    custom_config = json.load(f)
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                self._deep_update(default_config, custom_config)
                logger.info(f"Configuration loaded from: {config_file}")
                
            except Exception as e:
                logger.warning(f"Failed to load config file {config_file}: {e}")
                logger.info("Using default configuration")
        
        return default_config
    
    def _deep_update(self, base_dict: Dict, update_dict: Dict):
        """–ì–ª—É–±–æ–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è"""
        for key, value in update_dict.items():
            if key in base_dict and isinstance(base_dict[key], dict) and isinstance(value, dict):
                self._deep_update(base_dict[key], value)
            else:
                base_dict[key] = value
    
    def _setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        log_config = self.config.get('logging', {})
        log_level = getattr(logging, log_config.get('level', 'INFO').upper())
        log_file = log_config.get('file', './logs/migration.log')
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤
        Path(log_file).parent.mkdir(parents=True, exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–≥–µ—Ä
        logging.basicConfig(
            level=log_level,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
    
    # =============================================================================
    # MAIN MIGRATION METHODS
    # =============================================================================
    
    def run_full_migration(self) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –º–∏–≥—Ä–∞—Ü–∏–∏
        """
        logger.info("üöÄ Starting full data migration")
        
        migration_result = {
            'migration_type': 'full',
            'start_time': datetime.utcnow().isoformat(),
            'config': self.config,
            'steps': {},
            'summary': {}
        }
        
        try:
            # –®–∞–≥ 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
            logger.info("üìã Step 1: Initialization")
            init_result = self._initialize_migration()
            migration_result['steps']['initialization'] = init_result
            
            if init_result.get('error'):
                migration_result['error'] = init_result['error']
                return migration_result
            
            # –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
            if self.config['database']['backup_before_migration']:
                logger.info("üíæ Step 2: Creating database backup")
                backup_result = self._create_backup()
                migration_result['steps']['backup'] = backup_result
            
            # –®–∞–≥ 3: –í–∞–ª–∏–¥–∞—Ü–∏—è –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if self.config['migration']['validation_enabled']:
                logger.info("‚úÖ Step 3: Validating source data")
                validation_result = self._validate_source_data()
                migration_result['steps']['validation'] = validation_result
                
                if validation_result.get('critical_errors', 0) > 0:
                    migration_result['error'] = "Critical validation errors found"
                    return migration_result
            
            # –®–∞–≥ 4: –û—Å–Ω–æ–≤–Ω–∞—è –º–∏–≥—Ä–∞—Ü–∏—è
            logger.info("üîÑ Step 4: Main data migration")
            main_migration_result = self._run_main_migration()
            migration_result['steps']['main_migration'] = main_migration_result
            
            if main_migration_result.get('error'):
                migration_result['error'] = main_migration_result['error']
                return migration_result
            
            # –®–∞–≥ 5: –ü–æ—Å—Ç-–º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
            if self.config['migration']['validation_enabled']:
                logger.info("üîç Step 5: Post-migration validation")
                post_validation_result = self._validate_migrated_data()
                migration_result['steps']['post_validation'] = post_validation_result
            
            # –®–∞–≥ 6: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
            logger.info("üìä Step 6: Generating migration report")
            report_result = self._generate_migration_report(migration_result)
            migration_result['steps']['report_generation'] = report_result
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–≤–æ–¥–∫–∞
            end_time = datetime.utcnow()
            start_time = datetime.fromisoformat(migration_result['start_time'])
            duration = (end_time - start_time).total_seconds()
            
            migration_result['summary'] = {
                'end_time': end_time.isoformat(),
                'duration_seconds': duration,
                'success': True,
                'files_processed': main_migration_result.get('statistics', {}).get('total_files_processed', 0),
                'products_migrated': main_migration_result.get('statistics', {}).get('total_products_imported', 0),
                'duplicates_found': main_migration_result.get('statistics', {}).get('duplicates_merged', 0)
            }
            
            logger.info(f"‚úÖ Full migration completed successfully in {duration:.2f} seconds")
            
        except Exception as e:
            logger.error(f"‚ùå Migration failed: {e}")
            migration_result['error'] = str(e)
            migration_result['summary'] = {
                'end_time': datetime.utcnow().isoformat(),
                'success': False,
                'error': str(e)
            }
        
        return migration_result
    
    def run_incremental_migration(self, data_directory: str) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã)
        
        Args:
            data_directory: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –º–∏–≥—Ä–∞—Ü–∏–∏
        """
        logger.info(f"üîÑ Starting incremental migration from: {data_directory}")
        
        migration_result = {
            'migration_type': 'incremental',
            'start_time': datetime.utcnow().isoformat(),
            'data_directory': data_directory,
            'steps': {}
        }
        
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
            init_result = self._initialize_migration()
            if init_result.get('error'):
                migration_result['error'] = init_result['error']
                return migration_result
            
            # –ü–æ–∏—Å–∫ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
            logger.info("üîç Finding new files")
            new_files = self._find_new_files(data_directory)
            migration_result['steps']['file_discovery'] = {
                'new_files_found': len(new_files),
                'files': [str(f) for f in new_files]
            }
            
            if not new_files:
                logger.info("No new files found for migration")
                migration_result['summary'] = {
                    'end_time': datetime.utcnow().isoformat(),
                    'success': True,
                    'files_processed': 0,
                    'message': 'No new files to process'
                }
                return migration_result
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
            logger.info(f"üìÑ Processing {len(new_files)} new files")
            processing_result = self._process_files_batch(new_files)
            migration_result['steps']['file_processing'] = processing_result
            
            # –°–≤–æ–¥–∫–∞
            end_time = datetime.utcnow()
            start_time = datetime.fromisoformat(migration_result['start_time'])
            duration = (end_time - start_time).total_seconds()
            
            migration_result['summary'] = {
                'end_time': end_time.isoformat(),
                'duration_seconds': duration,
                'success': True,
                'files_processed': len(new_files),
                'products_added': processing_result.get('total_products_integrated', 0)
            }
            
            logger.info(f"‚úÖ Incremental migration completed in {duration:.2f} seconds")
            
        except Exception as e:
            logger.error(f"‚ùå Incremental migration failed: {e}")
            migration_result['error'] = str(e)
        
        return migration_result
    
    # =============================================================================
    # STEP IMPLEMENTATIONS
    # =============================================================================
    
    def _initialize_migration(self) -> Dict[str, Any]:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏"""
        try:
            # –°–æ–∑–¥–∞–µ–º adapter
            database_url = self.config['database']['url']
            self.integration_adapter = LegacyIntegrationAdapter(database_url)
            
            # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            self._create_directories()
            
            return {
                'success': True,
                'database_url': database_url,
                'directories_created': True
            }
            
        except Exception as e:
            logger.error(f"Initialization failed: {e}")
            return {'error': str(e)}
    
    def _create_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        dirs_to_create = [
            './logs',
            './reports',
            './backups',
            self.config['migration']['data_directory']
        ]
        
        for dir_path in dirs_to_create:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    def _create_backup(self) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            database_url = self.config['database']['url']
            
            if database_url.startswith('sqlite:'):
                # –î–ª—è SQLite —Å–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é —Ñ–∞–π–ª–∞
                db_file = database_url.replace('sqlite:///', '')
                if Path(db_file).exists():
                    backup_file = f"./backups/backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
                    
                    import shutil
                    shutil.copy2(db_file, backup_file)
                    
                    return {
                        'success': True,
                        'backup_file': backup_file,
                        'original_size': Path(db_file).stat().st_size
                    }
            else:
                # –î–ª—è –¥—Ä—É–≥–∏—Ö –ë–î –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pg_dump, mysqldump –∏ —Ç.–¥.
                logger.warning("Backup not implemented for non-SQLite databases")
                return {
                    'success': False,
                    'message': 'Backup not implemented for this database type'
                }
            
            return {'success': True, 'message': 'No database file to backup'}
            
        except Exception as e:
            logger.error(f"Backup creation failed: {e}")
            return {'error': str(e)}
    
    def _validate_source_data(self) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            from migrations.migration_validator import MigrationValidator
            
            validator = MigrationValidator()
            data_directory = self.config['migration']['data_directory']
            
            validation_result = validator.validate_source_directory(data_directory)
            
            return validation_result
            
        except Exception as e:
            logger.error(f"Source data validation failed: {e}")
            return {
                'error': str(e),
                'critical_errors': 1
            }
    
    def _run_main_migration(self) -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–∞—è –º–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        try:
            data_directory = self.config['migration']['data_directory']
            file_patterns = self.config['migration']['file_patterns']
            
            migration_result = self.integration_adapter.migrate_legacy_data_to_unified(
                data_directory, file_patterns
            )
            
            return migration_result
            
        except Exception as e:
            logger.error(f"Main migration failed: {e}")
            return {'error': str(e)}
    
    def _validate_migrated_data(self) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –º–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            from migrations.migration_validator import MigrationValidator
            
            validator = MigrationValidator()
            validation_result = validator.validate_unified_database(
                self.integration_adapter.db_manager
            )
            
            return validation_result
            
        except Exception as e:
            logger.error(f"Post-migration validation failed: {e}")
            return {'error': str(e)}
    
    def _generate_migration_report(self, migration_result: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –º–∏–≥—Ä–∞—Ü–∏–∏"""
        try:
            report_file = self.config['output']['report_file']
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –æ—Ç—á–µ—Ç–∞
            Path(report_file).parent.mkdir(parents=True, exist_ok=True)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –æ—Ç—á–µ—Ç
            enhanced_report = {
                **migration_result,
                'system_info': {
                    'python_version': sys.version,
                    'working_directory': str(Path.cwd()),
                    'config_used': self.config
                }
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(enhanced_report, f, indent=2, ensure_ascii=False)
            
            logger.info(f"Migration report saved to: {report_file}")
            
            return {
                'success': True,
                'report_file': report_file,
                'report_size': Path(report_file).stat().st_size
            }
            
        except Exception as e:
            logger.error(f"Report generation failed: {e}")
            return {'error': str(e)}
    
    def _find_new_files(self, data_directory: str) -> List[Path]:
        """–ü–æ–∏—Å–∫ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏"""
        import glob
        
        data_dir = Path(data_directory)
        if not data_dir.exists():
            return []
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
        all_files = []
        for pattern in self.config['migration']['file_patterns']:
            all_files.extend(glob.glob(str(data_dir / pattern)))
        
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
        # –ù–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–∏, —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞, —Ö–µ—à–∞ –∏ —Ç.–¥.
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
        
        return [Path(f) for f in all_files]
    
    def _process_files_batch(self, files: List[Path]) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–∫–µ—Ç–∞ —Ñ–∞–π–ª–æ–≤"""
        try:
            file_paths = [str(f) for f in files]
            
            result = self.integration_adapter.parser_adapter.process_multiple_files(
                file_paths, auto_match_duplicates=True
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Batch processing failed: {e}")
            return {'error': str(e)}


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(description='Monito Data Migration Script')
    
    parser.add_argument(
        '--config', '-c',
        type=str,
        help='Path to configuration file'
    )
    
    parser.add_argument(
        '--mode', '-m',
        choices=['full', 'incremental'],
        default='full',
        help='Migration mode (default: full)'
    )
    
    parser.add_argument(
        '--data-directory', '-d',
        type=str,
        help='Data directory for incremental migration'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Perform a dry run without actual migration'
    )
    
    args = parser.parse_args()
    
    try:
        # –°–æ–∑–¥–∞–µ–º –º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç
        migration_script = DataMigrationScript(args.config)
        
        if args.dry_run:
            print("üîç DRY RUN MODE - No actual migration will be performed")
            # –í dry-run —Ä–µ–∂–∏–º–µ –º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
            return
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –º–∏–≥—Ä–∞—Ü–∏—é
        if args.mode == 'full':
            result = migration_script.run_full_migration()
        else:  # incremental
            data_dir = args.data_directory or migration_script.config['migration']['data_directory']
            result = migration_script.run_incremental_migration(data_dir)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if result.get('error'):
            print(f"‚ùå Migration failed: {result['error']}")
            sys.exit(1)
        else:
            print("‚úÖ Migration completed successfully!")
            summary = result.get('summary', {})
            print(f"üìä Files processed: {summary.get('files_processed', 0)}")
            print(f"üì¶ Products migrated: {summary.get('products_migrated', 0)}")
            print(f"‚è±Ô∏è  Duration: {summary.get('duration_seconds', 0):.2f} seconds")
    
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Migration interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå Migration script failed: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main() 