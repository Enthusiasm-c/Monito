#!/usr/bin/env python3
"""
Row Validator V2 –¥–ª—è MON-003 - –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
–û—Å–Ω–æ–≤–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:
- Pandera schema validation –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
- Redis –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
- Intelligent data quality scoring
- Smart caching strategy –¥–ª—è –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Ç–æ–≤–∞—Ä–æ–≤
"""

import os
import time
import json
import hashlib
import logging
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass
from pathlib import Path
import pandas as pd

logger = logging.getLogger(__name__)

@dataclass
class ValidationStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è MON-003"""
    input_rows: int = 0
    valid_rows: int = 0
    invalid_rows: int = 0
    cached_hits: int = 0
    cached_misses: int = 0
    validation_time_ms: int = 0
    cache_time_ms: int = 0
    quality_score: float = 0.0
    errors: List[str] = None

    def __post_init__(self):
        if self.errors is None:
            self.errors = []

class RowValidatorV2:
    """
    Row Validator V2 –¥–ª—è MON-003 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    
    –ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:
    - üìä Pandera schema validation
    - üíæ Redis –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    - ‚úÖ Intelligent data quality scoring
    - üîÑ Smart caching strategy
    """
    
    def __init__(self, redis_host: str = 'localhost', redis_port: int = 6379, 
                 redis_db: int = 0, cache_ttl: int = 3600):
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = ValidationStats()
        
        # Redis –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.redis_host = redis_host
        self.redis_port = redis_port
        self.redis_db = redis_db
        self.cache_ttl = cache_ttl  # TTL –∫—ç—à–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (1 —á–∞—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
        self.min_quality_score = 0.7  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–∏–µ–º–ª–µ–º—ã–π score
        self.price_tolerance = 0.01   # –î–æ–ø—É—Å—Ç–∏–º–∞—è –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å —Ü–µ–Ω
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        self._check_dependencies()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Redis –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        self._init_redis()
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ö–µ–º—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        self._init_validation_schemas()
        
        logger.info("‚úÖ RowValidatorV2 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å MON-003 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏")
    
    def _check_dependencies(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π MON-003"""
        self.pandera_available = False
        self.redis_available = False
        
        try:
            import pandera as pa
            self.pandera_available = True
            logger.info("‚úÖ Pandera –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è schema validation")
        except ImportError:
            logger.warning("‚ö†Ô∏è Pandera –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–∞–ª–∏–¥–∞—Ü–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞")
        
        try:
            import redis
            self.redis_available = True
            logger.info("‚úÖ Redis –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è")
        except ImportError:
            logger.warning("‚ö†Ô∏è Redis –Ω–µ –Ω–∞–π–¥–µ–Ω, –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ")
    
    def _init_redis(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"""
        self.redis_client = None
        
        if not self.redis_available:
            logger.info("üìù Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ")
            return
        
        try:
            import redis
            
            self.redis_client = redis.Redis(
                host=self.redis_host,
                port=self.redis_port,
                db=self.redis_db,
                decode_responses=True,
                socket_timeout=5,
                socket_connect_timeout=5
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
            self.redis_client.ping()
            logger.info(f"‚úÖ Redis –ø–æ–¥–∫–ª—é—á–µ–Ω: {self.redis_host}:{self.redis_port}")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Redis: {e}")
            self.redis_client = None
    
    def _init_validation_schemas(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å Pandera"""
        if not self.pandera_available:
            logger.info("üìù Pandera –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é")
            return
        
        try:
            import pandera as pa
            
            # –°—Ö–µ–º–∞ –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤
            self.product_schema = pa.DataFrameSchema({
                'original_name': pa.Column(
                    str, 
                    checks=[
                        pa.Check.str_length(min_value=2, max_value=200),
                        pa.Check(lambda s: s.str.strip().str.len() > 0, 
                                error="Empty product names not allowed")
                    ],
                    nullable=False
                ),
                'price': pa.Column(
                    float,
                    checks=[
                        pa.Check.greater_than(0, error="Price must be positive"),
                        pa.Check.less_than(1000000, error="Price too high")
                    ],
                    nullable=False
                ),
                'unit': pa.Column(
                    str,
                    checks=[
                        pa.Check.isin(['pcs', 'kg', 'g', 'l', 'ml', 'm', 'cm', 'box', 'pack']),
                    ],
                    nullable=False
                ),
                'currency': pa.Column(
                    str,
                    checks=[
                        pa.Check.isin(['USD', 'EUR', 'RUB', 'CNY', 'GBP']),
                    ],
                    nullable=True
                )
            })
            
            # –°—Ö–µ–º–∞ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
            self.standardized_schema = pa.DataFrameSchema({
                'standardized_name': pa.Column(str, nullable=False),
                'brand': pa.Column(str, nullable=True),
                'category': pa.Column(str, nullable=True),
                'confidence': pa.Column(
                    float,
                    checks=[
                        pa.Check.between(0.0, 1.0, include_min=True, include_max=True)
                    ],
                    nullable=False
                )
            })
            
            logger.info("‚úÖ Pandera —Å—Ö–µ–º—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω—ã")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ö–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
            self.product_schema = None
            self.standardized_schema = None
    
    def validate_and_cache(self, df: pd.DataFrame, 
                          cache_key_prefix: str = "products") -> Tuple[pd.DataFrame, ValidationStats]:
        """
        MON-003: –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        
        Args:
            df: DataFrame —Å —Ç–æ–≤–∞—Ä–∞–º–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            cache_key_prefix: –ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –∫–ª—é—á–µ–π –∫—ç—à–∞
        
        Returns:
            Tuple[pd.DataFrame, ValidationStats]: –í–∞–ª–∏–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        """
        start_time = time.time()
        
        try:
            logger.info(f"üîç MON-003: –ù–∞—á–∏–Ω–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é {len(df)} —Å—Ç—Ä–æ–∫")
            
            # –°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self.stats = ValidationStats()
            self.stats.input_rows = len(df)
            
            if df.empty:
                logger.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π DataFrame –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
                return df, self.stats
            
            # –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞ (MON-003.1)
            cached_df = self._check_cache(df, cache_key_prefix)
            
            # –®–∞–≥ 2: Schema validation (MON-003.2)
            valid_df = self._validate_schema(df)
            
            # –®–∞–≥ 3: Data quality scoring (MON-003.3)
            quality_score = self._calculate_quality_score(valid_df)
            
            # –®–∞–≥ 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à (MON-003.4)
            self._save_to_cache(valid_df, cache_key_prefix)
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_time = int((time.time() - start_time) * 1000)
            self.stats.validation_time_ms = total_time
            self.stats.quality_score = quality_score
            
            logger.info(f"‚úÖ MON-003 COMPLETED: {len(valid_df)} –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –∑–∞ {total_time}ms")
            logger.info(f"   üìä Quality score: {quality_score:.3f}")
            logger.info(f"   üíæ Cache hits: {self.stats.cached_hits}")
            
            return valid_df, self.stats
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            error_stats = ValidationStats()
            error_stats.input_rows = len(df)
            error_stats.errors.append(str(e))
            return df, error_stats
    
    def _check_cache(self, df: pd.DataFrame, cache_key_prefix: str) -> Optional[pd.DataFrame]:
        """
        MON-003.1: –ü—Ä–æ–≤–µ—Ä–∫–∞ Redis –∫—ç—à–∞
        –¶–µ–ª—å: –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö
        """
        if not self.redis_client:
            logger.info("üìù Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –∫—ç—à–∞")
            self.stats.cached_misses = len(df)
            return None
        
        start_time = time.time()
        
        try:
            logger.info(f"üíæ MON-003.1: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –¥–ª—è {len(df)} —Å—Ç—Ä–æ–∫")
            
            cached_results = []
            cache_hits = 0
            cache_misses = 0
            
            for idx, row in df.iterrows():
                # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è —Å—Ç—Ä–æ–∫–∏
                cache_key = self._generate_cache_key(row, cache_key_prefix)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
                cached_data = self.redis_client.get(cache_key)
                
                if cached_data:
                    try:
                        cached_row = json.loads(cached_data)
                        cached_results.append(cached_row)
                        cache_hits += 1
                    except json.JSONDecodeError:
                        cache_misses += 1
                        continue
                else:
                    cache_misses += 1
            
            cache_time = int((time.time() - start_time) * 1000)
            self.stats.cache_time_ms = cache_time
            self.stats.cached_hits = cache_hits
            self.stats.cached_misses = cache_misses
            
            logger.info(f"‚úÖ –ö—ç—à –ø—Ä–æ–≤–µ—Ä–µ–Ω –∑–∞ {cache_time}ms:")
            logger.info(f"   üíæ Hits: {cache_hits}")
            logger.info(f"   ‚ùå Misses: {cache_misses}")
            
            if cached_results:
                return pd.DataFrame(cached_results)
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫—ç—à–∞: {e}")
            self.stats.cached_misses = len(df)
            return None
    
    def _validate_schema(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        MON-003.2: Schema validation —Å Pandera
        –¶–µ–ª—å: –û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
        """
        if not self.pandera_available or not self.product_schema:
            logger.info("üìù Pandera –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é")
            return self._basic_validation(df)
        
        try:
            import pandera as pa
            
            logger.info(f"üìä MON-003.2: Schema validation...")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            df_to_validate = df.copy()
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –µ—Å—Ç—å
            required_columns = ['original_name', 'price', 'unit']
            missing_columns = [col for col in required_columns if col not in df_to_validate.columns]
            
            if missing_columns:
                logger.warning(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}")
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                for col in missing_columns:
                    if col == 'original_name':
                        df_to_validate[col] = 'Unknown Product'
                    elif col == 'price':
                        df_to_validate[col] = 0.0
                    elif col == 'unit':
                        df_to_validate[col] = 'pcs'
            
            # –î–æ–±–∞–≤–ª—è–µ–º currency –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
            if 'currency' not in df_to_validate.columns:
                df_to_validate['currency'] = 'USD'
            
            # –ü—Ä–∏–≤–æ–¥–∏–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
            df_to_validate['price'] = pd.to_numeric(df_to_validate['price'], errors='coerce')
            df_to_validate['original_name'] = df_to_validate['original_name'].astype(str)
            df_to_validate['unit'] = df_to_validate['unit'].astype(str)
            df_to_validate['currency'] = df_to_validate['currency'].astype(str)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ Pandera
            validated_df = self.product_schema.validate(df_to_validate, lazy=True)
            
            self.stats.valid_rows = len(validated_df)
            self.stats.invalid_rows = len(df) - len(validated_df)
            
            logger.info(f"‚úÖ Schema validation –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
            logger.info(f"   ‚úÖ –í–∞–ª–∏–¥–Ω—ã—Ö: {self.stats.valid_rows}")
            logger.info(f"   ‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö: {self.stats.invalid_rows}")
            
            return validated_df
            
        except pa.errors.SchemaErrors as e:
            logger.warning(f"‚ö†Ô∏è Schema validation errors:")
            
            # –°–æ–±–∏—Ä–∞–µ–º –æ—à–∏–±–∫–∏
            failure_cases = e.failure_cases
            error_messages = []
            
            for _, error_case in failure_cases.iterrows():
                error_msg = f"Row {error_case.get('index', 'N/A')}: {error_case.get('failure_case', 'Unknown error')}"
                error_messages.append(error_msg)
                logger.warning(f"   ‚Ä¢ {error_msg}")
            
            self.stats.errors.extend(error_messages[:10])  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–µ 10 –æ—à–∏–±–æ–∫
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            try:
                valid_data = e.data.dropna()
                self.stats.valid_rows = len(valid_data)
                self.stats.invalid_rows = len(df) - len(valid_data)
                return valid_data
            except:
                # Fallback –Ω–∞ –±–∞–∑–æ–≤—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é
                return self._basic_validation(df)
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ schema validation: {e}")
            return self._basic_validation(df)
    
    def _basic_validation(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –±–µ–∑ Pandera"""
        try:
            logger.info("üìù –í—ã–ø–æ–ª–Ω—è–µ–º –±–∞–∑–æ–≤—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é...")
            
            valid_df = df.copy()
            
            # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ —Ç–æ–≤–∞—Ä–æ–≤
            if 'original_name' in valid_df.columns:
                valid_df = valid_df[valid_df['original_name'].notna()]
                valid_df = valid_df[valid_df['original_name'].str.strip() != '']
            
            # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ —Ü–µ–Ω–∞–º–∏
            if 'price' in valid_df.columns:
                valid_df['price'] = pd.to_numeric(valid_df['price'], errors='coerce')
                valid_df = valid_df[valid_df['price'] > 0]
            
            self.stats.valid_rows = len(valid_df)
            self.stats.invalid_rows = len(df) - len(valid_df)
            
            logger.info(f"‚úÖ –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è: {self.stats.valid_rows}/{len(df)} —Å—Ç—Ä–æ–∫ –≤–∞–ª–∏–¥–Ω—ã")
            
            return valid_df
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –±–∞–∑–æ–≤–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
            self.stats.valid_rows = len(df)
            self.stats.invalid_rows = 0
            return df
    
    def _calculate_quality_score(self, df: pd.DataFrame) -> float:
        """
        MON-003.3: Intelligent data quality scoring
        –¶–µ–ª—å: –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –æ—Ç 0.0 –¥–æ 1.0
        """
        try:
            if df.empty:
                return 0.0
            
            logger.info(f"üìä MON-003.3: –†–∞—Å—á–µ—Ç quality score...")
            
            scores = []
            
            # 1. –ü–æ–ª–Ω–æ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö (completeness)
            required_columns = ['original_name', 'price', 'unit']
            completeness_scores = []
            
            for col in required_columns:
                if col in df.columns:
                    non_null_ratio = df[col].notna().sum() / len(df)
                    completeness_scores.append(non_null_ratio)
                else:
                    completeness_scores.append(0.0)
            
            completeness_score = sum(completeness_scores) / len(completeness_scores)
            scores.append(('completeness', completeness_score, 0.3))
            
            # 2. –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ü–µ–Ω (validity)
            price_validity = 0.0
            if 'price' in df.columns:
                valid_prices = df['price'] > 0
                price_validity = valid_prices.sum() / len(df) if len(df) > 0 else 0
            
            scores.append(('price_validity', price_validity, 0.25))
            
            # 3. –ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞–∑–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ (consistency)
            name_quality = 0.0
            if 'original_name' in df.columns:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –Ω–∞–∑–≤–∞–Ω–∏–π
                good_length = df['original_name'].str.len().between(3, 100)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç —Ç–æ–ª—å–∫–æ —á–∏—Å–µ–ª
                not_only_numbers = ~df['original_name'].str.match(r'^\d+$', na=False)
                
                name_quality = (good_length & not_only_numbers).sum() / len(df) if len(df) > 0 else 0
            
            scores.append(('name_quality', name_quality, 0.25))
            
            # 4. –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è (standardization)
            unit_standardization = 0.0
            if 'unit' in df.columns:
                standard_units = ['pcs', 'kg', 'g', 'l', 'ml', 'm', 'cm', 'box', 'pack']
                standardized = df['unit'].isin(standard_units)
                unit_standardization = standardized.sum() / len(df) if len(df) > 0 else 0
            
            scores.append(('unit_standardization', unit_standardization, 0.2))
            
            # –ò—Ç–æ–≥–æ–≤—ã–π –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π score
            total_score = sum(score * weight for name, score, weight in scores)
            
            logger.info(f"‚úÖ Quality score —Ä–∞—Å—Å—á–∏—Ç–∞–Ω: {total_score:.3f}")
            for name, score, weight in scores:
                logger.debug(f"   ‚Ä¢ {name}: {score:.3f} (–≤–µ—Å: {weight})")
            
            return round(total_score, 3)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ quality score: {e}")
            return 0.5  # –°—Ä–µ–¥–Ω–∏–π score –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    def _save_to_cache(self, df: pd.DataFrame, cache_key_prefix: str):
        """
        MON-003.4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Redis –∫—ç—à
        –¶–µ–ª—å: –£—Å–∫–æ—Ä–µ–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –æ–±—Ä–∞—â–µ–Ω–∏–π
        """
        if not self.redis_client or df.empty:
            logger.info("üìù Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è")
            return
        
        try:
            logger.info(f"üíæ MON-003.4: –°–æ—Ö—Ä–∞–Ω—è–µ–º {len(df)} —Å—Ç—Ä–æ–∫ –≤ –∫—ç—à...")
            
            saved_count = 0
            
            for idx, row in df.iterrows():
                cache_key = self._generate_cache_key(row, cache_key_prefix)
                cache_data = json.dumps(row.to_dict(), ensure_ascii=False)
                
                try:
                    self.redis_client.setex(cache_key, self.cache_ttl, cache_data)
                    saved_count += 1
                except Exception as e:
                    logger.debug(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫—ç—à: {e}")
                    continue
            
            logger.info(f"‚úÖ –í –∫—ç—à —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count}/{len(df)} —Å—Ç—Ä–æ–∫")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –∫—ç—à: {e}")
    
    def _generate_cache_key(self, row: pd.Series, prefix: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∫–ª—é—á–∞ –¥–ª—è –∫—ç—à–∞"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏ —Ü–µ–Ω—É –¥–ª—è –∫–ª—é—á–∞
            name = str(row.get('original_name', '')).strip().lower()
            price = str(row.get('price', ''))
            unit = str(row.get('unit', ''))
            
            # –°–æ–∑–¥–∞–µ–º —Ö—ç—à –¥–ª—è –∫–ª—é—á–∞
            data_string = f"{name}|{price}|{unit}"
            hash_object = hashlib.md5(data_string.encode('utf-8'))
            hash_hex = hash_object.hexdigest()
            
            return f"{prefix}:{hash_hex}"
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–ª—é—á–∞ –∫—ç—à–∞: {e}")
            return f"{prefix}:unknown_{int(time.time())}"
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫—ç—à–∞"""
        if not self.redis_client:
            return {'cache_available': False}
        
        try:
            info = self.redis_client.info()
            return {
                'cache_available': True,
                'redis_version': info.get('redis_version', 'unknown'),
                'used_memory_human': info.get('used_memory_human', 'unknown'),
                'connected_clients': info.get('connected_clients', 0),
                'keyspace_hits': info.get('keyspace_hits', 0),
                'keyspace_misses': info.get('keyspace_misses', 0),
                'cache_hit_ratio': round(
                    info.get('keyspace_hits', 0) / 
                    max(info.get('keyspace_hits', 0) + info.get('keyspace_misses', 0), 1), 3
                )
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫—ç—à–∞: {e}")
            return {'cache_available': True, 'error': str(e)}
    
    def clear_cache(self, pattern: str = None) -> int:
        """–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞"""
        if not self.redis_client:
            logger.warning("‚ö†Ô∏è Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–µ–ª—å–∑—è –æ—á–∏—Å—Ç–∏—Ç—å –∫—ç—à")
            return 0
        
        try:
            if pattern:
                keys = self.redis_client.keys(pattern)
                if keys:
                    deleted = self.redis_client.delete(*keys)
                    logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {deleted} –∫–ª—é—á–µ–π –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É {pattern}")
                    return deleted
                else:
                    logger.info(f"üìù –ö–ª—é—á–∏ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É {pattern} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    return 0
            else:
                self.redis_client.flushdb()
                logger.info("‚úÖ –í–µ—Å—å –∫—ç—à –æ—á–∏—â–µ–Ω")
                return -1  # –í—Å–µ –∫–ª—é—á–∏
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞: {e}")
            return 0
    
    def get_validation_report(self) -> Dict[str, Any]:
        """–û—Ç—á–µ—Ç –æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ MON-003"""
        return {
            'mon_003_validation': {
                'pandera_available': self.pandera_available,
                'redis_available': self.redis_available and self.redis_client is not None,
                'min_quality_score': self.min_quality_score,
                'cache_ttl_seconds': self.cache_ttl
            },
            'validation_stats': {
                'input_rows': self.stats.input_rows,
                'valid_rows': self.stats.valid_rows,
                'invalid_rows': self.stats.invalid_rows,
                'validation_time_ms': self.stats.validation_time_ms,
                'quality_score': self.stats.quality_score,
                'errors_count': len(self.stats.errors)
            },
            'cache_stats': {
                'cached_hits': self.stats.cached_hits,
                'cached_misses': self.stats.cached_misses,
                'cache_time_ms': self.stats.cache_time_ms,
                'cache_hit_ratio': round(
                    self.stats.cached_hits / 
                    max(self.stats.cached_hits + self.stats.cached_misses, 1), 3
                )
            },
            'version': 'RowValidatorV2_MON003'
        } 